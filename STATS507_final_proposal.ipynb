{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b035cc4-817c-4c59-a316-2bdd912bef11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, Seq2SeqTrainer, Seq2SeqTrainingArguments, DataCollatorForSeq2Seq\n",
    "\n",
    "egy_ds = load_dataset(\"QCRI/arabic_pos_dialect\", \"egy\")\n",
    "glf_ds = load_dataset(\"QCRI/arabic_pos_dialect\", \"glf\")\n",
    "lev_ds = load_dataset(\"QCRI/arabic_pos_dialect\", \"lev\")\n",
    "mgr_ds = load_dataset(\"QCRI/arabic_pos_dialect\", \"mgr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b44e4ee3-de2a-497c-a5c8-f4d7e8f7817d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, let's look at the data in a pandas DF\n",
    "egy_df = egy_ds['train'].to_pandas()\n",
    "glf_df = glf_ds['train'].to_pandas()\n",
    "lev_df = lev_ds['train'].to_pandas()\n",
    "mgr_df = mgr_ds['train'].to_pandas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76ddc902-1404-4ec9-a499-e480522b5599",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>subfold</th>\n",
       "      <th>words</th>\n",
       "      <th>segments</th>\n",
       "      <th>pos_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>A</td>\n",
       "      <td>[ููู, ููุง, ุชุญุจ, ุญุฏ, ูู, ููุจู, ูุทูุน, ูุงุทู, ููู,...</td>\n",
       "      <td>[ููู, ููุง, ุชุญุจ, ุญุฏ, ูู, ููุจ+ู, ูุทูุน, ูุงุทู, ููู...</td>\n",
       "      <td>[PART, PART, V, NOUN, PREP, NOUN+PRON, V, ADJ,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>A</td>\n",
       "      <td>[ุนุงุฑู, ุจููููู, ุงูู, \", ุฅุฐุง, ุฃุฎุทุฃุช, ูุฃุญุณู, \", ....</td>\n",
       "      <td>[ุนุงุฑู, ุจ+ููู+ู+ู, ุงูู, \", ุฅุฐุง, ุฃุฎุทุฃ+ุช, ู+ุฃุญุณู,...</td>\n",
       "      <td>[ADJ, PROG_PART+V+PREP+PRON, PART, PUNC, PART,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>A</td>\n",
       "      <td>[ุงูุญูุฏ, ููู, ูุง, ุฌุฏุนุงู, ุงููุฑุณุงู, ุงููู, ุงุชูุณููุง...</td>\n",
       "      <td>[ุงู+ุญูุฏ, ู+ุงููู, ูุง, ุฌุฏุนุงู, ุงู+ูุฑุณุงู, ุงููู, ุงุช...</td>\n",
       "      <td>[DET+NOUN, PREP+NOUN, PART, NOUN, DET+NOUN, PA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>[ุจุญุณ, ุจุดุฎุตูุชู, ุงููููุฉ, ููุง, ุงููู, ูุงุฎููุง, ุงุนูู...</td>\n",
       "      <td>[ุจ+ุญุณ, ุจ+ุดุฎุตู+ุช+ู, ุงู+ููู+ุฉ, ููุง, ุงููู, ู+ุงุฎู+...</td>\n",
       "      <td>[PROG_PART+V, PREP+NOUN+NSUFF+PRON, DET+ADJ+NS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>A</td>\n",
       "      <td>[@ahmedabodsheesh, ูุง, ุจุงุดุง, ุฏู, ูุด, ูุญุชุงุฌู, ุฏ...</td>\n",
       "      <td>[@ahmedabodsheesh, ูุง, ุจุงุดุง, ุฏู, ูุด, ูุญุชุงุฌ+ู, ...</td>\n",
       "      <td>[MENTION, PART, NOUN, PRON, PART, ADJ+NSUFF, N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "      <td>[ููู, ูุญุธุฉ, ูุฏุฉ, ู, ุงูุช, ูุงุนุฏ, ูุน, ูุงุณ, ุจุชุถุญู,...</td>\n",
       "      <td>[ู+ูู, ูุญุธ+ุฉ, ูุฏุฉ, ู, ุงูุช, ูุงุนุฏ, ูุน, ูุงุณ, ุจ+ุชุถ...</td>\n",
       "      <td>[CONJ+PREP, NOUN+NSUFF, ADV, CONJ, PRON, ADJ, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>5</td>\n",
       "      <td>B</td>\n",
       "      <td>[ุงููู, ุจูููู, ูุด, ูููุชุฎุจ, ุญูุฏูู, ุนุดุงู, ูุด, ููู...</td>\n",
       "      <td>[ุงููู, ุจ+ูููู, ูุด, ู+ููุชุฎุจ, ุญูุฏูู, ุนุดุงู, ูุด, ู...</td>\n",
       "      <td>[PART, PROG_PART+V, PART, FUT_PART+V, NOUN, PA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>4</td>\n",
       "      <td>B</td>\n",
       "      <td>[ููุฑูุถ, ูุงุชุฒุนูุด, ุนุดุงู, ูู, ูุงุณ, ุญุงููุง, ุงูุญุด, ู...</td>\n",
       "      <td>[ููุฑูุถ, ูุง+ุชุฒุนู+ุด, ุนุดุงู, ูู, ูุงุณ, ุญุงู+ูุง, ุงูุญุด...</td>\n",
       "      <td>[ADJ, PART+V+NEG_PART, PART, PREP, NOUN, NOUN+...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>5</td>\n",
       "      <td>B</td>\n",
       "      <td>[ุทุจ, ุฅุฏููุง, ูุฑุตุฉ, ูุญุท, ููุดุฉ, ุงููุดุงู, ูู, ุงูููุฑ...</td>\n",
       "      <td>[ุทุจ, ุฅุฏ+ู+ูุง, ูุฑุต+ุฉ, ูุญุท, ููุด+ุฉ, ุงู+ูุดุงู, ูู, ...</td>\n",
       "      <td>[ADJ, V+PRON+PRON, NOUN+NSUFF, V, NOUN+NSUFF, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "      <td>[ููุง, ุชุฒุนู, ูู, ุญุฏ, ูููู, ุฑุจูุง, ูุณุงูุญู, :), ุฃู...</td>\n",
       "      <td>[ููุง, ุชุฒุนู, ูู, ุญุฏ, ูู+ู+ู, ุฑุจ+ูุง, ูุณุงูุญ+ู, :)...</td>\n",
       "      <td>[PART, V, PREP, NOUN, V+PREP+PRON, NOUN+PRON, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>350 rows ร 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     fold subfold                                              words  \\\n",
       "0       4       A  [ููู, ููุง, ุชุญุจ, ุญุฏ, ูู, ููุจู, ูุทูุน, ูุงุทู, ููู,...   \n",
       "1       4       A  [ุนุงุฑู, ุจููููู, ุงูู, \", ุฅุฐุง, ุฃุฎุทุฃุช, ูุฃุญุณู, \", ....   \n",
       "2       3       A  [ุงูุญูุฏ, ููู, ูุง, ุฌุฏุนุงู, ุงููุฑุณุงู, ุงููู, ุงุชูุณููุง...   \n",
       "3       1       A  [ุจุญุณ, ุจุดุฎุตูุชู, ุงููููุฉ, ููุง, ุงููู, ูุงุฎููุง, ุงุนูู...   \n",
       "4       5       A  [@ahmedabodsheesh, ูุง, ุจุงุดุง, ุฏู, ูุด, ูุญุชุงุฌู, ุฏ...   \n",
       "..    ...     ...                                                ...   \n",
       "345     1       B  [ููู, ูุญุธุฉ, ูุฏุฉ, ู, ุงูุช, ูุงุนุฏ, ูุน, ูุงุณ, ุจุชุถุญู,...   \n",
       "346     5       B  [ุงููู, ุจูููู, ูุด, ูููุชุฎุจ, ุญูุฏูู, ุนุดุงู, ูุด, ููู...   \n",
       "347     4       B  [ููุฑูุถ, ูุงุชุฒุนูุด, ุนุดุงู, ูู, ูุงุณ, ุญุงููุง, ุงูุญุด, ู...   \n",
       "348     5       B  [ุทุจ, ุฅุฏููุง, ูุฑุตุฉ, ูุญุท, ููุดุฉ, ุงููุดุงู, ูู, ุงูููุฑ...   \n",
       "349     1       B  [ููุง, ุชุฒุนู, ูู, ุญุฏ, ูููู, ุฑุจูุง, ูุณุงูุญู, :), ุฃู...   \n",
       "\n",
       "                                              segments  \\\n",
       "0    [ููู, ููุง, ุชุญุจ, ุญุฏ, ูู, ููุจ+ู, ูุทูุน, ูุงุทู, ููู...   \n",
       "1    [ุนุงุฑู, ุจ+ููู+ู+ู, ุงูู, \", ุฅุฐุง, ุฃุฎุทุฃ+ุช, ู+ุฃุญุณู,...   \n",
       "2    [ุงู+ุญูุฏ, ู+ุงููู, ูุง, ุฌุฏุนุงู, ุงู+ูุฑุณุงู, ุงููู, ุงุช...   \n",
       "3    [ุจ+ุญุณ, ุจ+ุดุฎุตู+ุช+ู, ุงู+ููู+ุฉ, ููุง, ุงููู, ู+ุงุฎู+...   \n",
       "4    [@ahmedabodsheesh, ูุง, ุจุงุดุง, ุฏู, ูุด, ูุญุชุงุฌ+ู, ...   \n",
       "..                                                 ...   \n",
       "345  [ู+ูู, ูุญุธ+ุฉ, ูุฏุฉ, ู, ุงูุช, ูุงุนุฏ, ูุน, ูุงุณ, ุจ+ุชุถ...   \n",
       "346  [ุงููู, ุจ+ูููู, ูุด, ู+ููุชุฎุจ, ุญูุฏูู, ุนุดุงู, ูุด, ู...   \n",
       "347  [ููุฑูุถ, ูุง+ุชุฒุนู+ุด, ุนุดุงู, ูู, ูุงุณ, ุญุงู+ูุง, ุงูุญุด...   \n",
       "348  [ุทุจ, ุฅุฏ+ู+ูุง, ูุฑุต+ุฉ, ูุญุท, ููุด+ุฉ, ุงู+ูุดุงู, ูู, ...   \n",
       "349  [ููุง, ุชุฒุนู, ูู, ุญุฏ, ูู+ู+ู, ุฑุจ+ูุง, ูุณุงูุญ+ู, :)...   \n",
       "\n",
       "                                              pos_tags  \n",
       "0    [PART, PART, V, NOUN, PREP, NOUN+PRON, V, ADJ,...  \n",
       "1    [ADJ, PROG_PART+V+PREP+PRON, PART, PUNC, PART,...  \n",
       "2    [DET+NOUN, PREP+NOUN, PART, NOUN, DET+NOUN, PA...  \n",
       "3    [PROG_PART+V, PREP+NOUN+NSUFF+PRON, DET+ADJ+NS...  \n",
       "4    [MENTION, PART, NOUN, PRON, PART, ADJ+NSUFF, N...  \n",
       "..                                                 ...  \n",
       "345  [CONJ+PREP, NOUN+NSUFF, ADV, CONJ, PRON, ADJ, ...  \n",
       "346  [PART, PROG_PART+V, PART, FUT_PART+V, NOUN, PA...  \n",
       "347  [ADJ, PART+V+NEG_PART, PART, PREP, NOUN, NOUN+...  \n",
       "348  [ADJ, V+PRON+PRON, NOUN+NSUFF, V, NOUN+NSUFF, ...  \n",
       "349  [PART, V, PREP, NOUN, V+PREP+PRON, NOUN+PRON, ...  \n",
       "\n",
       "[350 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "egy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cc0a23b-5eb4-4d9f-a644-e989c043be40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>subfold</th>\n",
       "      <th>words</th>\n",
       "      <th>segments</th>\n",
       "      <th>pos_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>B</td>\n",
       "      <td>[@tagimlm77, @444Tf, ูู, ุซุนูุจ, ููุงุฑ, ุจุนุฏ, ุดูู,...</td>\n",
       "      <td>[@tagimlm77, @444Tf, ูู, ุซุนูุจ, ููุงุฑ, ุจุนุฏ, ุดูู,...</td>\n",
       "      <td>[MENTION, MENTION, PRON, NOUN, ADJ, NOUN, ADJ,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>B</td>\n",
       "      <td>[ุตุฏุฒ, ูุงูุงู, ุงู, ุฑูุญุฉ, ุงูุนูุฏ, ุชูุนูุด, ููุงูู, ุชุฎ...</td>\n",
       "      <td>[ุตุฏุฒ, ูุง+ูุงู, ุงู, ุฑูุญ+ุฉ, ุงู+ุนูุฏ, ุชูุนูุด, ู+ูุง+ู...</td>\n",
       "      <td>[NOUN, PART+V, PART, NOUN+NSUFF, DET+NOUN, V, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "      <td>[ูุง, ุชููุฑูู, ุจุงููุงุถู, ุนุดุงู, ูุง, ุชุชุถุงูููู, ููุง,...</td>\n",
       "      <td>[ูุง, ุชููุฑ+ูู, ุจ+ุงู+ูุงุถู, ุนุดุงู, ูุง, ุชุชุถุงูู+ูู, ...</td>\n",
       "      <td>[PART, V+PRON, PREP+DET+NOUN, PART, PART, V+PR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>B</td>\n",
       "      <td>[@chanyol_, ุงู, ูุงููู, ุงุนุฑู, ูุญุฏู, ูุฐุง, ูุฏุฑุฌู,...</td>\n",
       "      <td>[@chanyol_, ุงู, ู+ุงููู, ุงุนุฑู, ูุญุฏ+ู, ูุฐุง, ู+ุฏุฑ...</td>\n",
       "      <td>[MENTION, PART, CONJ+NOUN, V, NOUN+NSUFF, ADV,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>A</td>\n",
       "      <td>[ูู, ุนุขูู, ุงูุดุนุฑ, ูุงูุฃุถูุขุก, ูุงูุดูุฑู, ูุงููุขูุน, ...</td>\n",
       "      <td>[ูู, ุนุขูู, ุงู+ุดุนุฑ, ู+ุงู+ุฃุถูุขุก, ู+ุงูุดูุฑู, ู+ุงู+...</td>\n",
       "      <td>[PREP, NOUN, DET+NOUN, CONJ+DET+NOUN, CONJ+NOU...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "      <td>[@Ghazi_alsmiri, ูุงููุง, ูููุฉ, ุบูุง, ุ, ุ, ูุณุงู,...</td>\n",
       "      <td>[@Ghazi_alsmiri, ูุง+ููุง, ู+ูู+ุฉ, ุบูุง, ุ, ุ, ูุณ...</td>\n",
       "      <td>[MENTION, PART+NOUN, CONJ+NUM+NSUFF, NOUN, PUN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>3</td>\n",
       "      <td>A</td>\n",
       "      <td>[ุงูุซุฑ, ุดู, ุฌุฐุจูู, ููุญุฉ, ุงูุณูุงุฑุฉ, ููููู, ุฑูู, ุฌ...</td>\n",
       "      <td>[ุงูุซุฑ, ุดู, ุฌุฐุจ+ูู, ููุญ+ุฉ, ุงู+ุณูุงุฑ+ุฉ, ููููู, ุฑู...</td>\n",
       "      <td>[ADJ, NOUN, V+PRON, NOUN+NSUFF, DET+NOUN+NSUFF...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>3</td>\n",
       "      <td>B</td>\n",
       "      <td>[ุฏุงููุง, ุงูุดุฎุต, ุงููู, ููุชูุฏู, ูุซูุฑ, ุญุงูู, ูููู,...</td>\n",
       "      <td>[ุฏุงูู+ุง, ุงู+ุดุฎุต, ุงููู, ููุชูุฏ+ู, ูุซูุฑ, ุญุงูู, ูู...</td>\n",
       "      <td>[ADJ+CASE, DET+NOUN, PART, V+PRON, ADJ, V, V, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "      <td>[ุชุฑู, ููุง, ุงูุชุจ, ุชุบุฑูุฏู, ูู, ูุนูู, ุงูู, ูุงุถูู,...</td>\n",
       "      <td>[ุชุฑู, ููุง, ุงูุชุจ, ุชุบุฑูุฏ+ู, ูู, ูุนูู, ุงู+ู, ูุงุถู...</td>\n",
       "      <td>[PART, PART, V, NOUN+NSUFF, PART, V, PART+PRON...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>4</td>\n",
       "      <td>B</td>\n",
       "      <td>[@150M7mad, ุงููู, ููุฏูู, ุจุณ, ุชุฑุง, ูู, ุฎูู, ูุงู...</td>\n",
       "      <td>[@150M7mad, ุงููู, ููุฏู+ู, ุจุณ, ุชุฑุง, ูู, ุฎูู, ู+...</td>\n",
       "      <td>[MENTION, NOUN, V+PRON, PART, PART, PART, NOUN...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>350 rows ร 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     fold subfold                                              words  \\\n",
       "0       2       B  [@tagimlm77, @444Tf, ูู, ุซุนูุจ, ููุงุฑ, ุจุนุฏ, ุดูู,...   \n",
       "1       3       B  [ุตุฏุฒ, ูุงูุงู, ุงู, ุฑูุญุฉ, ุงูุนูุฏ, ุชูุนูุด, ููุงูู, ุชุฎ...   \n",
       "2       1       B  [ูุง, ุชููุฑูู, ุจุงููุงุถู, ุนุดุงู, ูุง, ุชุชุถุงูููู, ููุง,...   \n",
       "3       4       B  [@chanyol_, ุงู, ูุงููู, ุงุนุฑู, ูุญุฏู, ูุฐุง, ูุฏุฑุฌู,...   \n",
       "4       5       A  [ูู, ุนุขูู, ุงูุดุนุฑ, ูุงูุฃุถูุขุก, ูุงูุดูุฑู, ูุงููุขูุน, ...   \n",
       "..    ...     ...                                                ...   \n",
       "345     1       B  [@Ghazi_alsmiri, ูุงููุง, ูููุฉ, ุบูุง, ุ, ุ, ูุณุงู,...   \n",
       "346     3       A  [ุงูุซุฑ, ุดู, ุฌุฐุจูู, ููุญุฉ, ุงูุณูุงุฑุฉ, ููููู, ุฑูู, ุฌ...   \n",
       "347     3       B  [ุฏุงููุง, ุงูุดุฎุต, ุงููู, ููุชูุฏู, ูุซูุฑ, ุญุงูู, ูููู,...   \n",
       "348     1       B  [ุชุฑู, ููุง, ุงูุชุจ, ุชุบุฑูุฏู, ูู, ูุนูู, ุงูู, ูุงุถูู,...   \n",
       "349     4       B  [@150M7mad, ุงููู, ููุฏูู, ุจุณ, ุชุฑุง, ูู, ุฎูู, ูุงู...   \n",
       "\n",
       "                                              segments  \\\n",
       "0    [@tagimlm77, @444Tf, ูู, ุซุนูุจ, ููุงุฑ, ุจุนุฏ, ุดูู,...   \n",
       "1    [ุตุฏุฒ, ูุง+ูุงู, ุงู, ุฑูุญ+ุฉ, ุงู+ุนูุฏ, ุชูุนูุด, ู+ูุง+ู...   \n",
       "2    [ูุง, ุชููุฑ+ูู, ุจ+ุงู+ูุงุถู, ุนุดุงู, ูุง, ุชุชุถุงูู+ูู, ...   \n",
       "3    [@chanyol_, ุงู, ู+ุงููู, ุงุนุฑู, ูุญุฏ+ู, ูุฐุง, ู+ุฏุฑ...   \n",
       "4    [ูู, ุนุขูู, ุงู+ุดุนุฑ, ู+ุงู+ุฃุถูุขุก, ู+ุงูุดูุฑู, ู+ุงู+...   \n",
       "..                                                 ...   \n",
       "345  [@Ghazi_alsmiri, ูุง+ููุง, ู+ูู+ุฉ, ุบูุง, ุ, ุ, ูุณ...   \n",
       "346  [ุงูุซุฑ, ุดู, ุฌุฐุจ+ูู, ููุญ+ุฉ, ุงู+ุณูุงุฑ+ุฉ, ููููู, ุฑู...   \n",
       "347  [ุฏุงูู+ุง, ุงู+ุดุฎุต, ุงููู, ููุชูุฏ+ู, ูุซูุฑ, ุญุงูู, ูู...   \n",
       "348  [ุชุฑู, ููุง, ุงูุชุจ, ุชุบุฑูุฏ+ู, ูู, ูุนูู, ุงู+ู, ูุงุถู...   \n",
       "349  [@150M7mad, ุงููู, ููุฏู+ู, ุจุณ, ุชุฑุง, ูู, ุฎูู, ู+...   \n",
       "\n",
       "                                              pos_tags  \n",
       "0    [MENTION, MENTION, PRON, NOUN, ADJ, NOUN, ADJ,...  \n",
       "1    [NOUN, PART+V, PART, NOUN+NSUFF, DET+NOUN, V, ...  \n",
       "2    [PART, V+PRON, PREP+DET+NOUN, PART, PART, V+PR...  \n",
       "3    [MENTION, PART, CONJ+NOUN, V, NOUN+NSUFF, ADV,...  \n",
       "4    [PREP, NOUN, DET+NOUN, CONJ+DET+NOUN, CONJ+NOU...  \n",
       "..                                                 ...  \n",
       "345  [MENTION, PART+NOUN, CONJ+NUM+NSUFF, NOUN, PUN...  \n",
       "346  [ADJ, NOUN, V+PRON, NOUN+NSUFF, DET+NOUN+NSUFF...  \n",
       "347  [ADJ+CASE, DET+NOUN, PART, V+PRON, ADJ, V, V, ...  \n",
       "348  [PART, PART, V, NOUN+NSUFF, PART, V, PART+PRON...  \n",
       "349  [MENTION, NOUN, V+PRON, PART, PART, PART, NOUN...  \n",
       "\n",
       "[350 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8fd2294-ea62-4ffc-87c8-aa4f9f3af479",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lev_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mlev_df\u001b[49m\n",
      "\u001b[31mNameError\u001b[39m: name 'lev_df' is not defined"
     ]
    }
   ],
   "source": [
    "lev_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ddaba1dd-2348-4294-8f80-b69085965e89",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mgr_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mmgr_df\u001b[49m\n",
      "\u001b[31mNameError\u001b[39m: name 'mgr_df' is not defined"
     ]
    }
   ],
   "source": [
    "mgr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80749c6b-245e-4753-9854-3265ca271e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, let's train a basic Seq2Seq Model. We take one sequence, and our output comes out\n",
    "# on the other side. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "8166c0dc-4d83-4674-8ec3-023f0239f2f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ๐ค Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "\n",
    "# First, we start with a Pretrained Model.\n",
    "# It is AraT5v2.\n",
    "model_name = \"UBC-NLP/AraT5v2-base-1024\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "max_length = 128\n",
    "\n",
    "\n",
    "# We take an example (segments, pos_tags)\n",
    "def preprocess_example(example):\n",
    "    model_inputs = tokenizer(\n",
    "        example[\"segments\"],\n",
    "        max_length=max_length,\n",
    "        truncation=True,\n",
    "        is_split_into_words=True\n",
    "    )\n",
    "\n",
    "    labels = tokenizer(\n",
    "        example[\"pos_tags\"],\n",
    "        max_length=max_length,\n",
    "        truncation=True,\n",
    "        is_split_into_words=True\n",
    "    )\n",
    "    \n",
    "    # pad model_inputs, labels, attn_mask\n",
    "    input_ids = np.pad(model_inputs[\"input_ids\"],\n",
    "                       (0, max_length - len(model_inputs[\"input_ids\"])),\n",
    "                       mode='constant')\n",
    "    label_ids = np.pad(labels[\"input_ids\"],\n",
    "                       (0, max_length - len(labels[\"input_ids\"])),\n",
    "                       mode='constant')\n",
    "    attn_mask = np.pad(model_inputs[\"attention_mask\"],\n",
    "                       (0, max_length - len(model_inputs[\"attention_mask\"])),\n",
    "                       mode='constant')\n",
    "\n",
    "    # Return it in dictionary forms\n",
    "    return {\n",
    "        \"input_ids\": input_ids,\n",
    "        \"labels\": label_ids,\n",
    "        \"attention_mask\": attn_mask\n",
    "    }\n",
    "\n",
    "# Make a DF (350 x 3) of our data.\n",
    "rows = [preprocess_example(ex) for ex in egy_ds[\"train\"]]\n",
    "df = pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./seq2seq_output\",           # Required: directory for saving model checkpoints\n",
    "    num_train_epochs=1,                      # Total number of training epochs\n",
    "    per_device_train_batch_size=2,           # Batch size per device during training\n",
    "    per_device_eval_batch_size=2,            # Batch size for evaluation\n",
    "    learning_rate=2e-5,                      # The initial learning rate\n",
    "    weight_decay=0.01,                       # Strength of weight decay\n",
    "    logging_dir=\"./logs\",                    # Directory for storing logs\n",
    "    predict_with_generate=True,              # Use generate to compute the evaluation metrics\n",
    "    evaluation_strategy=\"steps\",  \t\t\t # Evaluate every `eval_steps`\n",
    "    eval_steps=500,\n",
    "    use_mps_device=False\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "ds = Dataset.from_pandas(df.copy())\n",
    "\n",
    "from transformers import AutoModelForSeq2SeqLM\n",
    "import evaluate\n",
    "\n",
    "model_name = \"UBC-NLP/AraT5v2-base-1024\"\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "\n",
    "accuracy_metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions = eval_pred.predictions\n",
    "    label_ids = eval_pred.label_ids\n",
    "    new_predictions = []\n",
    "    new_label_ids = []\n",
    "    for prediction in predictions:\n",
    "        new_prediction = np.pad(prediction, (0, max_length - len(prediction)), mode='constant')\n",
    "        new_predictions.append(new_prediction)\n",
    "    for label_id in label_ids:\n",
    "    \tnew_label_id = np.pad(label_id, (0, max_length - len(label_id)), mode='constant')\n",
    "    \tnew_label_ids.append(new_label_id)\n",
    "    new_predictions = np.array(new_predictions)\n",
    "    new_label_ids = np.array(new_label_ids)\n",
    "    return accuracy_metric.compute(predictions=new_predictions.flatten(), references=new_label_ids.flatten())\n",
    "\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=ds,\n",
    "    eval_dataset=ds,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "# Start training\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "cdb8edc8-e537-4481-acd5-56ac1343d98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = trainer.evaluate()\n",
    "# TODO: FIX UP\n",
    "# {'eval_loss': 5.768518924713135,\n",
    "# 'eval_accuracy': 0.2711607142857143,\n",
    "# 'eval_runtime': 166.6632,\n",
    "# 'eval_samples_per_second': 2.1,\n",
    "# 'eval_steps_per_second': 1.05,\n",
    "# 'epoch': 1.0}\n",
    "# stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "b0c4b1a0-3aea-4a46-aacf-7b3647f4069a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Bar Plot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "labels = list(stats.keys())\n",
    "values = list(stats.values())\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "bars = plt.bar(labels, values)\n",
    "\n",
    "# Add labels on top of each bar\n",
    "for bar, value in zip(bars, values):\n",
    "    height = bar.get_height()\n",
    "    plt.text(\n",
    "        bar.get_x() + bar.get_width() / 2,\n",
    "        height,\n",
    "        f\"{value:.3f}\",\n",
    "        ha='center',\n",
    "        va='bottom'\n",
    "    )\n",
    "\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.ylabel(\"Value\")\n",
    "plt.title(\"Evaluation Statistics\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "db73c1d0-2d0b-4add-8bfa-9f2608e7db22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import PreTrainedModel\n",
    "from transformers.modeling_outputs import Seq2SeqLMOutput\n",
    "\n",
    "# Now, we will experiment with custom architecture.\n",
    "# This is an example of a basic, bare bones, neural network.\n",
    "\n",
    "\n",
    "# Vocab size.\n",
    "# There are ~44800 vocabulary words in arabic.\n",
    "vocab_size = 44800\n",
    "\n",
    "# \n",
    "# This is our custom Sequence2Sequence model. \n",
    "#\n",
    "# The embeddings layers is first - there is\n",
    "# no matric multiplication, but it maps our\n",
    "# R^(1x128) input_ids to a R^(128x206) embeddings matrix\n",
    "# (if we have up to 128 tokens, embeddings up to 206 for the hidden layer).\n",
    "#\n",
    "# The linear layer is a typical linear layer.\n",
    "# W is a matrix R^(206x44800)\n",
    "# b is a bias term, R^(44800).\n",
    "# output = xW + b, R^(128x44800)\n",
    "#\n",
    "class MySeq2SeqModel(PreTrainedModel):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.embed = nn.Embedding(vocab_size, 206)\n",
    "        self.linear = nn.Linear(206, vocab_size)\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, input_ids=None, attention_mask=None, labels=None, **kwargs):\n",
    "        x = self.embed(input_ids)\n",
    "        logits = self.linear(x)\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss = self.loss_fn(\n",
    "                logits.view(-1, vocab_size),\n",
    "                labels.view(-1)\n",
    "            )\n",
    "        return Seq2SeqLMOutput(logits=logits, loss=loss)\n",
    "\n",
    "\n",
    "# Define our training args.\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./out\",\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=1,\n",
    "    fp16=False,               \n",
    "    bf16=False,\n",
    "    dataloader_pin_memory=False,\n",
    "    dataloader_num_workers=0,\n",
    "    predict_with_generate=False\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "669ebaaf-a3fd-48b8-867b-a4fbbc71bcd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0187a1e554aa46a188c2bb3ba8ab17aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/350 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='282' max='1050' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 282/1050 07:46 < 21:18, 0.60 it/s, Epoch 0.80/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[150]\u001b[39m\u001b[32m, line 51\u001b[39m\n\u001b[32m     38\u001b[39m \u001b[38;5;66;03m# print(ds[0][\"input_ids\"].shape)\u001b[39;00m\n\u001b[32m     39\u001b[39m \u001b[38;5;66;03m# print(ds[0][\"labels\"].shape)          \u001b[39;00m\n\u001b[32m     40\u001b[39m \u001b[38;5;66;03m# print(ds[0][\"attention_mask\"].shape)\u001b[39;00m\n\u001b[32m     43\u001b[39m trainer = Seq2SeqTrainer(\n\u001b[32m     44\u001b[39m     model=model,\n\u001b[32m     45\u001b[39m     args=training_args,\n\u001b[32m   (...)\u001b[39m\u001b[32m     48\u001b[39m     compute_metrics=compute_metrics\n\u001b[32m     49\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/trainer.py:2171\u001b[39m, in \u001b[36mTrainer.train\u001b[39m\u001b[34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[39m\n\u001b[32m   2169\u001b[39m         hf_hub_utils.enable_progress_bars()\n\u001b[32m   2170\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2171\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2172\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2173\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2174\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2175\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2176\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/trainer.py:2584\u001b[39m, in \u001b[36mTrainer._inner_training_loop\u001b[39m\u001b[34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[39m\n\u001b[32m   2580\u001b[39m         grad_norm = _grad_norm\n\u001b[32m   2582\u001b[39m \u001b[38;5;28mself\u001b[39m.control = \u001b[38;5;28mself\u001b[39m.callback_handler.on_pre_optimizer_step(args, \u001b[38;5;28mself\u001b[39m.state, \u001b[38;5;28mself\u001b[39m.control)\n\u001b[32m-> \u001b[39m\u001b[32m2584\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2586\u001b[39m \u001b[38;5;28mself\u001b[39m.control = \u001b[38;5;28mself\u001b[39m.callback_handler.on_optimizer_step(args, \u001b[38;5;28mself\u001b[39m.state, \u001b[38;5;28mself\u001b[39m.control)\n\u001b[32m   2588\u001b[39m optimizer_was_run = \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.accelerator.optimizer_step_was_skipped\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/accelerate/optimizer.py:178\u001b[39m, in \u001b[36mAcceleratedOptimizer.step\u001b[39m\u001b[34m(self, closure)\u001b[39m\n\u001b[32m    176\u001b[39m         \u001b[38;5;28mself\u001b[39m._accelerate_step_called = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    177\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m178\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.accelerator_state.distributed_type == DistributedType.XLA:\n\u001b[32m    180\u001b[39m     \u001b[38;5;28mself\u001b[39m.gradient_state.is_xla_gradients_synced = \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:130\u001b[39m, in \u001b[36mLRScheduler.__init__.<locals>.patch_track_step_called.<locals>.wrap_step.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    128\u001b[39m opt = opt_ref()\n\u001b[32m    129\u001b[39m opt._opt_called = \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m130\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__get__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__class__\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/optim/optimizer.py:484\u001b[39m, in \u001b[36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    479\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    480\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    481\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    482\u001b[39m             )\n\u001b[32m--> \u001b[39m\u001b[32m484\u001b[39m out = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    485\u001b[39m \u001b[38;5;28mself\u001b[39m._optimizer_step_code()\n\u001b[32m    487\u001b[39m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/optim/optimizer.py:89\u001b[39m, in \u001b[36m_use_grad_for_differentiable.<locals>._use_grad\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     87\u001b[39m     torch.set_grad_enabled(\u001b[38;5;28mself\u001b[39m.defaults[\u001b[33m\"\u001b[39m\u001b[33mdifferentiable\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     88\u001b[39m     torch._dynamo.graph_break()\n\u001b[32m---> \u001b[39m\u001b[32m89\u001b[39m     ret = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     90\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     91\u001b[39m     torch._dynamo.graph_break()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/optim/adamw.py:227\u001b[39m, in \u001b[36mAdamW.step\u001b[39m\u001b[34m(self, closure)\u001b[39m\n\u001b[32m    214\u001b[39m     beta1, beta2 = cast(Tuple[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m], group[\u001b[33m\"\u001b[39m\u001b[33mbetas\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m    216\u001b[39m     has_complex = \u001b[38;5;28mself\u001b[39m._init_group(\n\u001b[32m    217\u001b[39m         group,\n\u001b[32m    218\u001b[39m         params_with_grad,\n\u001b[32m   (...)\u001b[39m\u001b[32m    224\u001b[39m         state_steps,\n\u001b[32m    225\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m227\u001b[39m     \u001b[43madamw\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    228\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    229\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    230\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    231\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    232\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    233\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    234\u001b[39m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    235\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    236\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweight_decay\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    239\u001b[39m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43meps\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    240\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmaximize\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    241\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mforeach\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    242\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcapturable\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    243\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdifferentiable\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    244\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfused\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    245\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgrad_scale\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    246\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfound_inf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    247\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    248\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    250\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/optim/optimizer.py:161\u001b[39m, in \u001b[36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    159\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m disabled_func(*args, **kwargs)\n\u001b[32m    160\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m161\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/optim/adamw.py:767\u001b[39m, in \u001b[36madamw\u001b[39m\u001b[34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[39m\n\u001b[32m    764\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    765\u001b[39m     func = _single_tensor_adamw\n\u001b[32m--> \u001b[39m\u001b[32m767\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    768\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    769\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    770\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    771\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    772\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    773\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    774\u001b[39m \u001b[43m    \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    775\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    776\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    777\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    778\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    779\u001b[39m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[43m=\u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    780\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    781\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    782\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    783\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    784\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    785\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    786\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/optim/adamw.py:434\u001b[39m, in \u001b[36m_single_tensor_adamw\u001b[39m\u001b[34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable, has_complex)\u001b[39m\n\u001b[32m    431\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    432\u001b[39m         denom = (exp_avg_sq.sqrt() / bias_correction2_sqrt).add_(eps)\n\u001b[32m--> \u001b[39m\u001b[32m434\u001b[39m     \u001b[43mparam\u001b[49m\u001b[43m.\u001b[49m\u001b[43maddcdiv_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexp_avg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdenom\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m=\u001b[49m\u001b[43m-\u001b[49m\u001b[43mstep_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    436\u001b[39m \u001b[38;5;66;03m# Lastly, switch back to complex view\u001b[39;00m\n\u001b[32m    437\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m amsgrad \u001b[38;5;129;01mand\u001b[39;00m torch.is_complex(params[i]):\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Now, we need to clean off our dataset for our custom model.\n",
    "ds = Dataset.from_pandas(df.copy())\n",
    "import torch\n",
    "\n",
    "MAX_LEN = 128\n",
    "\n",
    "def fix_dataset(batch):\n",
    "    input_ids = []\n",
    "    labels = []\n",
    "    attention_mask = []\n",
    "\n",
    "    for i in range(len(batch[\"input_ids\"])):\n",
    "        # input_ids\n",
    "        ids = batch[\"input_ids\"][i][:MAX_LEN]\n",
    "        ids += [0] * (MAX_LEN - len(ids))\n",
    "        input_ids.append(ids)\n",
    "\n",
    "        # labels\n",
    "        lab = batch[\"labels\"][i][:MAX_LEN]\n",
    "        lab += [0] * (MAX_LEN - len(lab))\n",
    "        labels.append(lab)\n",
    "\n",
    "        # attention_mask\n",
    "        mask = batch[\"attention_mask\"][i][:MAX_LEN]\n",
    "        mask += [0] * (MAX_LEN - len(mask))\n",
    "        attention_mask.append(mask)\n",
    "\n",
    "    # Convert to tensors\n",
    "    return {\n",
    "        \"input_ids\": torch.tensor(input_ids, dtype=torch.long),\n",
    "        \"labels\": torch.tensor(labels, dtype=torch.long),\n",
    "        \"attention_mask\": torch.tensor(attention_mask, dtype=torch.long)\n",
    "    }\n",
    "\n",
    "ds = ds.map(fix_row, batched=True)\n",
    "ds.set_format(type=\"torch\", columns=[\"input_ids\", \"labels\", \"attention_mask\"])\n",
    "\n",
    "# print(ds[0][\"input_ids\"].shape)\n",
    "# print(ds[0][\"labels\"].shape)          \n",
    "# print(ds[0][\"attention_mask\"].shape)\n",
    "\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=ds,\n",
    "    eval_dataset=ds,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "52b5ce57-470d-4332-a203-9957a1713666",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58bb0e2a372f4f6d990b19e5103b20ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/50 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "PredictionOutput(predictions=(array([[[ 2.24499726e+00,  3.67912602e+00,  2.11355042e+00, ...,\n",
       "          3.56623113e-01,  2.60196388e-01,  3.20772141e-01],\n",
       "        [-6.39338064e+00,  2.58325434e+00,  4.69725561e+00, ...,\n",
       "         -6.92879581e+00, -6.93278217e+00, -6.91557693e+00],\n",
       "        [-1.12956572e+01,  2.98897672e+00,  3.98833990e+00, ...,\n",
       "         -1.16057730e+01, -1.15919828e+01, -1.15701933e+01],\n",
       "        ...,\n",
       "        [ 2.86349854e+02, -1.81049690e+01, -4.86113968e+01, ...,\n",
       "          2.65654510e+02,  2.65115479e+02,  2.65387238e+02],\n",
       "        [ 2.86347198e+02, -1.80947399e+01, -4.85976868e+01, ...,\n",
       "          2.65651825e+02,  2.65113312e+02,  2.65385162e+02],\n",
       "        [ 2.86266327e+02, -1.80978146e+01, -4.85758209e+01, ...,\n",
       "          2.65571960e+02,  2.65034851e+02,  2.65306976e+02]],\n",
       "\n",
       "       [[ 2.28803182e+00,  4.21343851e+00,  2.92150998e+00, ...,\n",
       "          4.03914630e-01,  3.05631906e-01,  3.72353137e-01],\n",
       "        [-1.09501486e+01,  6.56614780e+00,  6.61931944e+00, ...,\n",
       "         -1.10905781e+01, -1.10431757e+01, -1.10370045e+01],\n",
       "        [-9.86968136e+00,  6.19043827e+00,  4.86647558e+00, ...,\n",
       "         -1.02450476e+01, -1.02528315e+01, -1.02186775e+01],\n",
       "        ...,\n",
       "        [ 2.82424011e+02, -1.55400801e+01, -4.66674118e+01, ...,\n",
       "          2.61658875e+02,  2.61113770e+02,  2.61414307e+02],\n",
       "        [ 2.82732819e+02, -1.56560783e+01, -4.67324409e+01, ...,\n",
       "          2.61957520e+02,  2.61408325e+02,  2.61712341e+02],\n",
       "        [ 2.83165680e+02, -1.57963161e+01, -4.67555313e+01, ...,\n",
       "          2.62395325e+02,  2.61845184e+02,  2.62148224e+02]],\n",
       "\n",
       "       [[ 1.83750284e+00,  3.69678903e+00,  2.57894421e+00, ...,\n",
       "         -2.48245858e-02, -1.17600635e-01, -5.33500686e-02],\n",
       "        [-4.51977348e+00,  4.02814817e+00,  8.64396191e+00, ...,\n",
       "         -4.76991701e+00, -4.77761698e+00, -4.75337505e+00],\n",
       "        [-1.20206079e+01,  7.14815092e+00,  7.13103533e+00, ...,\n",
       "         -1.20594101e+01, -1.20938511e+01, -1.20563364e+01],\n",
       "        ...,\n",
       "        [ 2.85461182e+02, -1.65187550e+01, -4.74553719e+01, ...,\n",
       "          2.64500427e+02,  2.63940338e+02,  2.64214081e+02],\n",
       "        [ 2.85446930e+02, -1.65553913e+01, -4.74341698e+01, ...,\n",
       "          2.64492004e+02,  2.63931366e+02,  2.64206207e+02],\n",
       "        [ 2.85350555e+02, -1.66507645e+01, -4.74753609e+01, ...,\n",
       "          2.64410248e+02,  2.63849579e+02,  2.64126648e+02]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 1.77160442e+00,  3.92545867e+00,  2.83739328e+00, ...,\n",
       "         -8.35995525e-02, -1.71512499e-01, -1.11192495e-01],\n",
       "        [-7.18708897e+00,  2.56232095e+00,  5.82449865e+00, ...,\n",
       "         -7.68173313e+00, -7.68594837e+00, -7.65878296e+00],\n",
       "        [-1.22618732e+01,  3.24912524e+00,  4.71832943e+00, ...,\n",
       "         -1.25808353e+01, -1.25655022e+01, -1.25301151e+01],\n",
       "        ...,\n",
       "        [-4.56158400e+00,  1.40805655e+01,  5.69794941e+00, ...,\n",
       "         -4.92561579e+00, -4.93221045e+00, -4.90800619e+00],\n",
       "        [-1.30557232e+01,  2.06963730e+01,  7.50675154e+00, ...,\n",
       "         -1.32001915e+01, -1.31444702e+01, -1.31717834e+01],\n",
       "        [-7.38785505e+00,  1.49675198e+01,  4.89200068e+00, ...,\n",
       "         -7.78936434e+00, -7.80212021e+00, -7.77654505e+00]],\n",
       "\n",
       "       [[ 1.78947127e+00,  4.02520275e+00,  2.53741741e+00, ...,\n",
       "         -7.48744234e-02, -1.75182879e-01, -1.04059674e-01],\n",
       "        [-1.13077602e+01,  6.44089270e+00,  6.79292154e+00, ...,\n",
       "         -1.13849239e+01, -1.13359861e+01, -1.13242874e+01],\n",
       "        [-9.96227455e+00,  6.40987492e+00,  4.69252586e+00, ...,\n",
       "         -1.03341074e+01, -1.03337536e+01, -1.03057480e+01],\n",
       "        ...,\n",
       "        [ 2.88083221e+02, -1.62213345e+01, -4.70978622e+01, ...,\n",
       "          2.67078033e+02,  2.66526489e+02,  2.66768890e+02],\n",
       "        [ 2.88094116e+02, -1.62090778e+01, -4.71034279e+01, ...,\n",
       "          2.67084015e+02,  2.66536316e+02,  2.66775269e+02],\n",
       "        [ 2.88026611e+02, -1.63206310e+01, -4.70970039e+01, ...,\n",
       "          2.67023895e+02,  2.66476288e+02,  2.66718811e+02]],\n",
       "\n",
       "       [[ 1.94146037e+00,  4.06560469e+00,  3.04665804e+00, ...,\n",
       "          7.24507719e-02, -2.34535653e-02,  4.08086218e-02],\n",
       "        [-7.14131498e+00,  2.64025068e+00,  5.83548880e+00, ...,\n",
       "         -7.62811756e+00, -7.63466978e+00, -7.61275148e+00],\n",
       "        [-1.13927345e+01,  3.61097407e+00,  4.87230778e+00, ...,\n",
       "         -1.17162409e+01, -1.17067137e+01, -1.16813726e+01],\n",
       "        ...,\n",
       "        [ 2.83131927e+02, -1.59289722e+01, -4.79086838e+01, ...,\n",
       "          2.62391174e+02,  2.61841125e+02,  2.62141968e+02],\n",
       "        [ 2.83103912e+02, -1.58788652e+01, -4.78484650e+01, ...,\n",
       "          2.62381805e+02,  2.61830200e+02,  2.62136108e+02],\n",
       "        [ 2.83753754e+02, -1.59541769e+01, -4.77663574e+01, ...,\n",
       "          2.63017273e+02,  2.62459595e+02,  2.62768890e+02]]],\n",
       "      dtype=float32), array([[[ 0.12745048,  0.6069345 ,  1.5989716 , ..., -0.7054666 ,\n",
       "          0.0877012 , -0.33079   ],\n",
       "        [-0.02722638, -0.79157215,  1.4075854 , ..., -0.1189491 ,\n",
       "         -0.746631  ,  0.17478658],\n",
       "        [-0.08261307, -0.34138674,  0.9981643 , ...,  0.07943109,\n",
       "         -0.74126035,  0.5626966 ],\n",
       "        ...,\n",
       "        [-0.20530078, -0.11779564, -0.15894257, ..., -1.4637095 ,\n",
       "         -0.28588843, -0.32364273],\n",
       "        [-0.05219471, -0.06746244, -0.25083855, ..., -1.5694278 ,\n",
       "         -0.34568682, -0.36055315],\n",
       "        [-0.09769746, -0.034896  , -0.23269662, ..., -1.6046455 ,\n",
       "         -0.34031326, -0.3793236 ]],\n",
       "\n",
       "       [[ 0.45288244, -0.12337086,  0.22709644, ..., -0.7737721 ,\n",
       "         -0.40557265,  1.0952003 ],\n",
       "        [-0.33765054,  0.2594156 ,  1.1815273 , ..., -0.91397005,\n",
       "         -0.88448817,  0.7534772 ],\n",
       "        [ 0.10627044, -0.8547251 ,  1.6998019 , ..., -1.2002484 ,\n",
       "         -0.41181037,  0.1378193 ],\n",
       "        ...,\n",
       "        [ 0.07699651, -0.03664732, -0.05015882, ..., -0.04644695,\n",
       "          0.03952292,  0.02039988],\n",
       "        [ 0.07614109, -0.03643789, -0.04980795, ..., -0.04645949,\n",
       "          0.03958775,  0.0202095 ],\n",
       "        [ 0.07398912, -0.03766808, -0.04887629, ..., -0.04463639,\n",
       "          0.03890736,  0.0203348 ]],\n",
       "\n",
       "       [[-0.00678976, -0.19324334,  2.487733  , ..., -0.7592189 ,\n",
       "         -1.133618  ,  0.6452821 ],\n",
       "        [ 0.05483954, -0.39355883,  1.9952432 , ..., -0.93151575,\n",
       "          0.02189041,  0.27014118],\n",
       "        [ 0.44314927,  0.29008603, -1.179497  , ..., -1.3904969 ,\n",
       "         -0.46083844,  0.61514384],\n",
       "        ...,\n",
       "        [ 0.13249318, -0.0069117 , -0.06810798, ..., -0.07537596,\n",
       "          0.05096419,  0.01740798],\n",
       "        [ 0.13194495, -0.00732057, -0.06729677, ..., -0.07400143,\n",
       "          0.0515966 ,  0.01654566],\n",
       "        [ 0.13363843, -0.00617568, -0.06857632, ..., -0.07444682,\n",
       "          0.05164878,  0.01715681]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-0.5394358 , -0.19785248,  1.6821969 , ..., -1.2697766 ,\n",
       "         -0.7029508 ,  1.5278058 ],\n",
       "        [-0.6021261 , -0.49276513,  0.5825036 , ..., -0.6179025 ,\n",
       "         -0.7605331 ,  1.0412285 ],\n",
       "        [-0.23330764, -0.6184706 ,  2.0705378 , ..., -0.7830006 ,\n",
       "          0.02693125,  0.30503547],\n",
       "        ...,\n",
       "        [ 0.02601026, -0.06265867, -0.04561517, ..., -0.02113189,\n",
       "          0.06242653,  0.02021464],\n",
       "        [ 0.02876868, -0.06140351, -0.04594596, ..., -0.02308284,\n",
       "          0.06418334,  0.01972515],\n",
       "        [ 0.0271928 , -0.06166492, -0.04683926, ..., -0.02144829,\n",
       "          0.06275324,  0.01998559]],\n",
       "\n",
       "       [[-0.00362039,  0.25674516,  0.5292921 , ...,  0.0595504 ,\n",
       "         -0.1189765 ,  0.21763176],\n",
       "        [ 0.09970176, -0.5396692 ,  1.9569767 , ..., -0.6843169 ,\n",
       "         -0.18929768,  0.4315794 ],\n",
       "        [ 0.6870569 , -0.12134223, -0.8418596 , ..., -1.2660347 ,\n",
       "         -0.2250693 , -0.08244887],\n",
       "        ...,\n",
       "        [ 0.12313703, -0.01721527, -0.05492055, ..., -0.06480216,\n",
       "          0.06096203,  0.02724355],\n",
       "        [ 0.12313703, -0.01721527, -0.05492055, ..., -0.06480216,\n",
       "          0.06096203,  0.02724355],\n",
       "        [ 0.12313703, -0.01721527, -0.05492055, ..., -0.06480216,\n",
       "          0.06096203,  0.02724355]],\n",
       "\n",
       "       [[ 0.01621663,  0.3314949 ,  1.4750353 , ..., -0.90453416,\n",
       "         -0.79102355,  0.63906837],\n",
       "        [ 0.24255662, -0.60409516,  1.8029408 , ..., -0.78145695,\n",
       "         -0.2970452 ,  0.18206002],\n",
       "        [ 0.10727532,  0.6899853 ,  0.01326766, ..., -2.3005095 ,\n",
       "         -0.08660353,  0.11179092],\n",
       "        ...,\n",
       "        [ 0.06674545, -0.03831434, -0.05605478, ..., -0.03625957,\n",
       "          0.04869343,  0.01753183],\n",
       "        [ 0.06295431, -0.04074233, -0.05347953, ..., -0.03276474,\n",
       "          0.04846044,  0.01662391],\n",
       "        [ 0.05966447, -0.04213925, -0.05235777, ..., -0.03079376,\n",
       "          0.04740641,  0.01654638]]], dtype=float32)), label_ids=array([[   163,  67494,    163, ...,      0,      0,      0],\n",
       "       [ 20162, 109668,  25829, ...,      0,      0,      0],\n",
       "       [   206,  16317, 109775, ...,      0,      0,      0],\n",
       "       ...,\n",
       "       [   163,  67494,    414, ...,  24172, 109654,      1],\n",
       "       [ 20162, 109668, 109775, ...,      0,      0,      0],\n",
       "       [   163,  67494, 109775, ...,      0,      0,      0]]), metrics={'test_loss': 0.5580077171325684, 'test_runtime': 12.8017, 'test_samples_per_second': 3.906, 'test_steps_per_second': 0.547})"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One option is to obtain predictions from the\n",
    "# predictions method.\n",
    "df_fixed = df.iloc[0:50]copy().reset_index(drop=True)\n",
    "ds = Dataset.from_pandas(df_fixed, preserve_index=False)\n",
    "ds = ds.map(fix_dataset, batched=True)\n",
    "ds.set_format(type=\"torch\", columns=[\"input_ids\", \"labels\", \"attention_mask\"])\n",
    "predictions = trainer.predict(ds)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4a286e38-f31b-4816-88b9-b89e767baaae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 3)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "e7f18da0-8228-427a-a1d2-958e0b339312",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7771c15c7d824182825f30390231bb35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/50 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "Placeholder storage has not been allocated on MPS device!",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[140]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m ds = ds.map(fix_row, batched=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m      5\u001b[39m ds.set_format(\u001b[38;5;28mtype\u001b[39m=\u001b[33m\"\u001b[39m\u001b[33mtorch\u001b[39m\u001b[33m\"\u001b[39m, columns=[\u001b[33m\"\u001b[39m\u001b[33minput_ids\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mlabels\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mattention_mask\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m stats = \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/trainer_seq2seq.py:197\u001b[39m, in \u001b[36mSeq2SeqTrainer.evaluate\u001b[39m\u001b[34m(self, eval_dataset, ignore_keys, metric_key_prefix, **gen_kwargs)\u001b[39m\n\u001b[32m    195\u001b[39m \u001b[38;5;28mself\u001b[39m.gather_function = \u001b[38;5;28mself\u001b[39m.accelerator.gather\n\u001b[32m    196\u001b[39m \u001b[38;5;28mself\u001b[39m._gen_kwargs = gen_kwargs\n\u001b[32m--> \u001b[39m\u001b[32m197\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43meval_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/trainer.py:4076\u001b[39m, in \u001b[36mTrainer.evaluate\u001b[39m\u001b[34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[39m\n\u001b[32m   4073\u001b[39m start_time = time.time()\n\u001b[32m   4075\u001b[39m eval_loop = \u001b[38;5;28mself\u001b[39m.prediction_loop \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args.use_legacy_prediction_loop \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.evaluation_loop\n\u001b[32m-> \u001b[39m\u001b[32m4076\u001b[39m output = \u001b[43meval_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4077\u001b[39m \u001b[43m    \u001b[49m\u001b[43meval_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4078\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mEvaluation\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   4079\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# No point gathering the predictions if there are no metrics, otherwise we defer to\u001b[39;49;00m\n\u001b[32m   4080\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# self.args.prediction_loss_only\u001b[39;49;00m\n\u001b[32m   4081\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprediction_loss_only\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   4082\u001b[39m \u001b[43m    \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4083\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4084\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4086\u001b[39m total_batch_size = \u001b[38;5;28mself\u001b[39m.args.eval_batch_size * \u001b[38;5;28mself\u001b[39m.args.world_size\n\u001b[32m   4087\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric_key_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_jit_compilation_time\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m output.metrics:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/trainer.py:4270\u001b[39m, in \u001b[36mTrainer.evaluation_loop\u001b[39m\u001b[34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[39m\n\u001b[32m   4267\u001b[39m         batch_size = observed_batch_size\n\u001b[32m   4269\u001b[39m \u001b[38;5;66;03m# Prediction step\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m4270\u001b[39m losses, logits, labels = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mprediction_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction_loss_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4271\u001b[39m main_input_name = \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.model, \u001b[33m\"\u001b[39m\u001b[33mmain_input_name\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33minput_ids\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   4272\u001b[39m inputs_decode = (\n\u001b[32m   4273\u001b[39m     \u001b[38;5;28mself\u001b[39m._prepare_input(inputs[main_input_name]) \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33minputs\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m args.include_for_metrics \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   4274\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/trainer_seq2seq.py:295\u001b[39m, in \u001b[36mSeq2SeqTrainer.prediction_step\u001b[39m\u001b[34m(self, model, inputs, prediction_loss_only, ignore_keys, **gen_kwargs)\u001b[39m\n\u001b[32m    271\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    272\u001b[39m \u001b[33;03mPerform an evaluation step on `model` using `inputs`.\u001b[39;00m\n\u001b[32m    273\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    291\u001b[39m \u001b[33;03m    labels (each being optional).\u001b[39;00m\n\u001b[32m    292\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    294\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args.predict_with_generate \u001b[38;5;129;01mor\u001b[39;00m prediction_loss_only:\n\u001b[32m--> \u001b[39m\u001b[32m295\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mprediction_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    296\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction_loss_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprediction_loss_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_keys\u001b[49m\n\u001b[32m    297\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    299\u001b[39m has_labels = \u001b[33m\"\u001b[39m\u001b[33mlabels\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m inputs\n\u001b[32m    300\u001b[39m inputs = \u001b[38;5;28mself\u001b[39m._prepare_inputs(inputs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/trainer.py:4486\u001b[39m, in \u001b[36mTrainer.prediction_step\u001b[39m\u001b[34m(self, model, inputs, prediction_loss_only, ignore_keys)\u001b[39m\n\u001b[32m   4484\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_labels \u001b[38;5;129;01mor\u001b[39;00m loss_without_labels:\n\u001b[32m   4485\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.compute_loss_context_manager():\n\u001b[32m-> \u001b[39m\u001b[32m4486\u001b[39m         loss, outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_outputs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   4487\u001b[39m     loss = loss.mean().detach()\n\u001b[32m   4489\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(outputs, \u001b[38;5;28mdict\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/trainer.py:3734\u001b[39m, in \u001b[36mTrainer.compute_loss\u001b[39m\u001b[34m(self, model, inputs, return_outputs, num_items_in_batch)\u001b[39m\n\u001b[32m   3732\u001b[39m         loss_kwargs[\u001b[33m\"\u001b[39m\u001b[33mnum_items_in_batch\u001b[39m\u001b[33m\"\u001b[39m] = num_items_in_batch\n\u001b[32m   3733\u001b[39m     inputs = {**inputs, **loss_kwargs}\n\u001b[32m-> \u001b[39m\u001b[32m3734\u001b[39m outputs = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3735\u001b[39m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[32m   3736\u001b[39m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[32m   3737\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args.past_index >= \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1551\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1552\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1553\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1557\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1558\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1559\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1560\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1561\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1562\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1564\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1565\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/models/t5/modeling_t5.py:1854\u001b[39m, in \u001b[36mT5ForConditionalGeneration.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[39m\n\u001b[32m   1851\u001b[39m \u001b[38;5;66;03m# Encode if needed (training, first prediction pass)\u001b[39;00m\n\u001b[32m   1852\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m encoder_outputs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1853\u001b[39m     \u001b[38;5;66;03m# Convert encoder inputs in embeddings if needed\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1854\u001b[39m     encoder_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1855\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1856\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1857\u001b[39m \u001b[43m        \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1858\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1859\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1860\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1861\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1862\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1863\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m return_dict \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(encoder_outputs, BaseModelOutput):\n\u001b[32m   1864\u001b[39m     encoder_outputs = BaseModelOutput(\n\u001b[32m   1865\u001b[39m         last_hidden_state=encoder_outputs[\u001b[32m0\u001b[39m],\n\u001b[32m   1866\u001b[39m         hidden_states=encoder_outputs[\u001b[32m1\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(encoder_outputs) > \u001b[32m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1867\u001b[39m         attentions=encoder_outputs[\u001b[32m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(encoder_outputs) > \u001b[32m2\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1868\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1551\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1552\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1553\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1557\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1558\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1559\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1560\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1561\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1562\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1564\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1565\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/models/t5/modeling_t5.py:1002\u001b[39m, in \u001b[36mT5Stack.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, cross_attn_head_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[39m\n\u001b[32m   1000\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.embed_tokens \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1001\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mYou have to initialize the model with valid token embeddings\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1002\u001b[39m     inputs_embeds = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43membed_tokens\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1004\u001b[39m batch_size, seq_length = input_shape\n\u001b[32m   1006\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m use_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1551\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1552\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1553\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1557\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1558\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1559\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1560\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1561\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1562\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1564\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1565\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/sparse.py:164\u001b[39m, in \u001b[36mEmbedding.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    163\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m164\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    166\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/functional.py:2267\u001b[39m, in \u001b[36membedding\u001b[39m\u001b[34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[39m\n\u001b[32m   2261\u001b[39m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[32m   2262\u001b[39m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[32m   2263\u001b[39m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[32m   2264\u001b[39m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[32m   2265\u001b[39m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[32m   2266\u001b[39m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[32m-> \u001b[39m\u001b[32m2267\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: Placeholder storage has not been allocated on MPS device!"
     ]
    }
   ],
   "source": [
    "# Stats from our new trainer.\n",
    "df_fixed = df.iloc[0:50].copy().reset_index(drop=True)\n",
    "ds = Dataset.from_pandas(df_fixed, preserve_index=False)\n",
    "ds = ds.map(fix_row, batched=True)\n",
    "ds.set_format(type=\"torch\", columns=[\"input_ids\", \"labels\", \"attention_mask\"])\n",
    "stats = trainer.evaluate(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "248509ec-f7b5-44e8-a387-a4367de733a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Bar Plot\n",
    "# We repeat from our first stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "labels = list(stats.keys())\n",
    "values = list(stats.values())\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "bars = plt.bar(labels, values)\n",
    "\n",
    "for bar, value in zip(bars, values):\n",
    "    height = bar.get_height()\n",
    "    plt.text(\n",
    "        bar.get_x() + bar.get_width() / 2,\n",
    "        height,\n",
    "        f\"{value:.3f}\",\n",
    "        ha='center',\n",
    "        va='bottom'\n",
    "    )\n",
    "\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.ylabel(\"Value\")\n",
    "plt.title(\"Evaluation Statistics\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1aead57d-f0b0-4919-a13d-f0122b8aef7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(350, 3)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "43e3d250-de95-4cdd-9a4d-eb6d0bef5301",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/training_args.py:1590: FutureWarning: using `no_cuda` is deprecated and will be removed in version 5.0 of ๐ค Transformers. Use `use_cpu` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Placeholder storage has not been allocated on MPS device!",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[129]\u001b[39m\u001b[32m, line 31\u001b[39m\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch.backends.mps.is_available():\n\u001b[32m     27\u001b[39m    torch.mps.empty_cache()\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/trainer.py:2171\u001b[39m, in \u001b[36mTrainer.train\u001b[39m\u001b[34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[39m\n\u001b[32m   2169\u001b[39m         hf_hub_utils.enable_progress_bars()\n\u001b[32m   2170\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2171\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2172\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2173\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2174\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2175\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2176\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/trainer.py:2531\u001b[39m, in \u001b[36mTrainer._inner_training_loop\u001b[39m\u001b[34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[39m\n\u001b[32m   2524\u001b[39m context = (\n\u001b[32m   2525\u001b[39m     functools.partial(\u001b[38;5;28mself\u001b[39m.accelerator.no_sync, model=model)\n\u001b[32m   2526\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m i != \u001b[38;5;28mlen\u001b[39m(batch_samples) - \u001b[32m1\u001b[39m\n\u001b[32m   2527\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.accelerator.distributed_type != DistributedType.DEEPSPEED\n\u001b[32m   2528\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m contextlib.nullcontext\n\u001b[32m   2529\u001b[39m )\n\u001b[32m   2530\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[32m-> \u001b[39m\u001b[32m2531\u001b[39m     tr_loss_step = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2533\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   2534\u001b[39m     args.logging_nan_inf_filter\n\u001b[32m   2535\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[32m   2536\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m (torch.isnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch.isinf(tr_loss_step))\n\u001b[32m   2537\u001b[39m ):\n\u001b[32m   2538\u001b[39m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[32m   2539\u001b[39m     tr_loss = tr_loss + tr_loss / (\u001b[32m1\u001b[39m + \u001b[38;5;28mself\u001b[39m.state.global_step - \u001b[38;5;28mself\u001b[39m._globalstep_last_logged)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/trainer.py:3678\u001b[39m, in \u001b[36mTrainer.training_step\u001b[39m\u001b[34m(self, model, inputs, num_items_in_batch)\u001b[39m\n\u001b[32m   3676\u001b[39m         loss = \u001b[38;5;28mself\u001b[39m.compute_loss(model, inputs)\n\u001b[32m   3677\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3678\u001b[39m         loss = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3680\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m inputs\n\u001b[32m   3681\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   3682\u001b[39m     \u001b[38;5;28mself\u001b[39m.args.torch_empty_cache_steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   3683\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.state.global_step % \u001b[38;5;28mself\u001b[39m.args.torch_empty_cache_steps == \u001b[32m0\u001b[39m\n\u001b[32m   3684\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/trainer.py:3734\u001b[39m, in \u001b[36mTrainer.compute_loss\u001b[39m\u001b[34m(self, model, inputs, return_outputs, num_items_in_batch)\u001b[39m\n\u001b[32m   3732\u001b[39m         loss_kwargs[\u001b[33m\"\u001b[39m\u001b[33mnum_items_in_batch\u001b[39m\u001b[33m\"\u001b[39m] = num_items_in_batch\n\u001b[32m   3733\u001b[39m     inputs = {**inputs, **loss_kwargs}\n\u001b[32m-> \u001b[39m\u001b[32m3734\u001b[39m outputs = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3735\u001b[39m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[32m   3736\u001b[39m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[32m   3737\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args.past_index >= \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1551\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1552\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1553\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1557\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1558\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1559\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1560\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1561\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1562\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1564\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1565\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/models/t5/modeling_t5.py:1854\u001b[39m, in \u001b[36mT5ForConditionalGeneration.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[39m\n\u001b[32m   1851\u001b[39m \u001b[38;5;66;03m# Encode if needed (training, first prediction pass)\u001b[39;00m\n\u001b[32m   1852\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m encoder_outputs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1853\u001b[39m     \u001b[38;5;66;03m# Convert encoder inputs in embeddings if needed\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1854\u001b[39m     encoder_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1855\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1856\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1857\u001b[39m \u001b[43m        \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1858\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1859\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1860\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1861\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1862\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1863\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m return_dict \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(encoder_outputs, BaseModelOutput):\n\u001b[32m   1864\u001b[39m     encoder_outputs = BaseModelOutput(\n\u001b[32m   1865\u001b[39m         last_hidden_state=encoder_outputs[\u001b[32m0\u001b[39m],\n\u001b[32m   1866\u001b[39m         hidden_states=encoder_outputs[\u001b[32m1\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(encoder_outputs) > \u001b[32m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1867\u001b[39m         attentions=encoder_outputs[\u001b[32m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(encoder_outputs) > \u001b[32m2\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1868\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1551\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1552\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1553\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1557\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1558\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1559\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1560\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1561\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1562\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1564\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1565\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/models/t5/modeling_t5.py:1002\u001b[39m, in \u001b[36mT5Stack.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, cross_attn_head_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[39m\n\u001b[32m   1000\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.embed_tokens \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1001\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mYou have to initialize the model with valid token embeddings\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1002\u001b[39m     inputs_embeds = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43membed_tokens\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1004\u001b[39m batch_size, seq_length = input_shape\n\u001b[32m   1006\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m use_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1551\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1552\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1553\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1557\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1558\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1559\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1560\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1561\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1562\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1564\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1565\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/sparse.py:164\u001b[39m, in \u001b[36mEmbedding.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    163\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m164\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    166\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/functional.py:2267\u001b[39m, in \u001b[36membedding\u001b[39m\u001b[34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[39m\n\u001b[32m   2261\u001b[39m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[32m   2262\u001b[39m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[32m   2263\u001b[39m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[32m   2264\u001b[39m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[32m   2265\u001b[39m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[32m   2266\u001b[39m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[32m-> \u001b[39m\u001b[32m2267\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: Placeholder storage has not been allocated on MPS device!"
     ]
    }
   ],
   "source": [
    "# CPU only trainer.\n",
    "\n",
    "import torch\n",
    "model_cpu = trainer.model.to(\"cpu\")\n",
    "\n",
    "accuracy_metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "padding_length = 130\n",
    "\n",
    "\n",
    "\n",
    "cpu_args = Seq2SeqTrainingArguments(\n",
    "   output_dir=\"./out\",\n",
    "   per_device_eval_batch_size=1,\n",
    "   predict_with_generate=False,\n",
    "   no_cuda=True               \n",
    ")\n",
    "\n",
    "cpu_trainer = Seq2SeqTrainer(\n",
    "   model=model_cpu,\n",
    "   args=cpu_args,\n",
    "   eval_dataset=ds\n",
    ")\n",
    "\n",
    "# Clear any leftover MPS cache\n",
    "if torch.backends.mps.is_available():\n",
    "   torch.mps.empty_cache()\n",
    "\n",
    "\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee10039-d7a3-470a-933b-734a07b055ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
